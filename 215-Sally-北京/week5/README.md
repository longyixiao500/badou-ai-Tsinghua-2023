### 立体视觉
1. 概论
    1. 定义：从两幅或两幅以上的图像中推理出图像中的每个像素点的深度信息
    2. 目的：以二维图像为基础，找到每个像素的距离
    3. 用处：
        1. 机器人
        2. 无人驾驶/辅助驾驶
        3. 无人机等
    4. 原理：左右眼视差
2. 单目系统
3. 双目系统
    1. 数学模型中的属性：
        1. 极平面
        2. 极点
        3. 基线
        4. 极线
    2. 经过一系列的初中数学运算(相似三角形原理)，引入视差（disparity）的概念
    3. 视差指的是：光源点和成像点的连线与相机平面的交点，在两个相机上距离最左侧距离的差值
    3. 注意
        1. 两个相机规格一样
        2. 两个相机不一定平行，可以带有角度
    4. 视差的定义：将同一空间物理点在不同图像中的影响点对应起来，这个差别称为视差（disparity）
        1. 根据公式，视差越大，物体距离越近，这与人类感知相符。

### 点云模型
1. 点云与三维图像
    1. 点云是最常见，也是最基础的三维模型
    2. 其他三维模型：
        1. 深度图：以灰度表达物体与相机的距离
        2. 几何模型：CAD软件
    3. 点云概念：目标表面特性的海量点集合，每一个点包含三维坐标，只包含物体表面的点，是空心的
    4. 点云的内容：
        1. 根据激光测距得到的点云：
            1. 三维坐标 XYZ
            2. 激光反射强度（Intensity）
        2. 根据摄影测量原理得到的点云：（摄像机测的）
            1. 三维坐标 XYZ
            2. 颜色信息 RGB
        3. 结合激光测量和摄影测量
            1. 三维坐标 XYZ
            2. 激光反射强度（Intensity）
            3. 颜色信息 RGB
    5. 点云处理的三个层次
        1. 低层次处理方法：
            1. 滤波方法：双边滤波、高斯滤波等
            2. 关键点检测：SIFT3D等
        2. 中层次处理方法：
            1. 特征描述：Spin image等
            2. 分割与分类
        3. 高层次处理方法：利用低层次和中层次组合实现的
    6. 重要算法
        1. Spin image
            1. 基于点云空间分布的最经典的特征描述方法
            2. 思想：将点云分布转为二维，输出结果被称为span image
            3. 生成spin image的步骤：
                1. 选取一个定向点（Oriented point）
                2. 以定向点为轴生成一个圆柱坐标系
                3. 定义Spin image的3个参数，Spin image是一个具有一定大小（行数列数）、分辨率（二维网格大小）的二维图像（或者说网格）
                    1. 分辨率，即二维网格的像素实际尺寸，取三位网格所有边的平均值来作为spin image 的每个网格尺寸(正方形)
                    2. 大小，即spin image的行数和列数，一般也相等，可以参考10 * 10、20 * 20
                    3. support angle，即法向量夹角的大小限制
                        1. 即另一个点 x 法向量与 n 的夹角 的限制，若大于support angle，则x点被抑制(即不被粘到纸上)
                        2. 一般限制在60°~90°
                        3. 目的在于降低后续计算量，只保留计算机需要的特征信息
            4. (前3步是准备工作，这一步开始生成spin image)
                1. 用一个平面绕着法线旋转获取点云的投射
                2. 凸面投射的点多，凹面投射的点少
                3. 通俗理解：一张胶纸转圈黏贴点
            5. 利用第4步得到的像素点进行反向双线性插值，将一个点分布到4个像素中，这样就得到了spin image

### 图像聚类算法
1. 分类与聚类
    1. 分类——有监督学习
        1. 定义：从特定的数据中挖掘模式，做出判断的过程
        2. 分类学习的过程
            1. 训练数据集存在一个类标记号，判断它是正i选哪个数据集(起积极作用)，还是负向数据集(起抑制作用)
            2. 然后需要对数据集进行学习训练，并构建一个训练的模型
            3. 通过该模型对预测数据集进行预测，并计算器结果的性能
        3. 重点
            1. 有历史数据、训练数据
            2. 训练数据集的每条数据都带标签，与聚类区分的重要标志，聚类没有标签
    2. 聚类——无监督学习
        1. 定义：从广义上说，聚类就是将数据集中在某些方面相似的数据成员放在一起
        2. 一个聚类就是一些数据实例的集合，其中处于相同聚类中的数据元素彼此相似，但是处于不同聚类中的元素彼此不同
        3. 由于在聚类中表示数据类别的分类或分组信息是没有的，即：
            1. 数据没有标签
            2. 因为没有标签，所以聚类通常被归为无监督学习（Unsupervised Learning）
            3. 需要根据人的经验给每个分类赋予意义
        4. 聚类样本间的属性
            1. 有序属性，如西瓜的甜度：0.1、0.5、0.9
            2. 无序属性：性别：男、女
        5. 聚类的常见算法：
            1. 原形聚类
                1. K均值聚类算法(K-Means)，最常用的聚类算法，没有之一
            2. 层次聚类
            3. 密度聚类
        6. K-Means聚类
            1. 概论：
                1. 最常用的聚类算法，没有之一
                2. 最初起源于信号处理，目标是将数据点划分为K个类簇
                3. 优点：简单、便于理解、运算速度快
                4. 缺点：要在聚类前人为指定聚类的类簇数
            2. k-means聚类算法的分析流程
                1. 确定K值：由人类主观确定，没有数学公式
                2. 随机选择K个数据点作为质心（Centroid）或数据中心
                3. 分别计算每个点到每个质心之间的距离，并将每个点划分到距离最近质心的小组
                    1. 一般来说是欧氏距离，用其他的自定义的距离也可以
                4. 当每个质心都聚集了一些点后，重新定义算法选出新的质心（对于每个簇，计算其均值，即得到新的k个质心）
                5. 迭代执行第3、4步，直到迭代终止条件满足为止（聚类结果不再变化）
            3. K-Means与图像处理
                1. 可以实现图像分割、图像聚类、图像识别等操作
                2. 用每个簇内的质心来替换簇内的所有像素点，实现在不改变分辨率的情况下量化压缩图像颜色，实现图像颜色的层级分割
            4. 优缺点
                1. 优点：
                    1. 解决聚类问题的经典算法，简单、快速
                    2. 对处理大数据集，该算法保持高效
                    3. 当结果簇是密集的，它的效果较好
                2. 缺点：
                    1. 必须事先给出K
                    1. 对噪声和孤立点非常敏感
        7. 层次聚类：针对K-Means缺点做出的改进
            1. 层次法，按层次分解的顺序分为
                1. 自底向上：凝聚的层次聚类算法
                2. 自顶向下：分裂的层次聚类算法
            2. 凝聚的层次聚类
                1. 流程
                    1. 将每个对象看作一类，计算两两之间的最小距离；
                        1. 这里并不是距离某一个特定的点的距离，而是算出每两个点之间的距离，取一个最小的距离对应的两个点
                    2. 将距离最小的两个类合并成一个新类；
                    3. 重新计算新类与所有类之间的距离；
                    4. 重复(2)、(3)，直到所有类最后合并成一类。
                2. 特点：
                    1. 没有类似K均值的全局目标函数，所以没有局部极小问题或是很难选择初始点的问题。
                    2. 合并操作不可逆
                    3. 计算存储代价昂贵，随着数据量增大，计算量呈几何倍数增长
            3. 树状图分类判断
                1. 想分两类时，就从上往下数有两根竖线时沿着横轴进行切割，那么所对应的数显下面所连接的为一类
                2. 优缺点
                    1. 优点：
                        1. 距离和规则的相似度容易定义，限制少
                        2. 不需要预先指定聚类数
                        3. 可以发现类的层次关系
                    2. 缺点：
                        1. 计算复杂度太高，这是一个很致命的缺点，所以K-Means用的更多
                        2. 算法很可能聚类成链状，即树状图退化成一条直线，跟缺点1比起来不致命，因为出现的少
            4. K-Means VS 层次聚类
                1. 服从高斯分布的数据适合K-Means聚类比较好
                2. 类别之间存在层结构的数据，用层次聚类比较好
                    1. 层结构举例：大学学科分类：一级学科、二级学科……
        8. 密度聚类（DBSCAN）：应用场景较少
            1. 需要人为设置两个参数，没有公式，经验也不管用，需要多次调整
                1. ε (eps)，即邻域半径
                2. 形成高密度区域所需要的最少点数 (minPts)，第一步画的邻域内点少于minPts则这个圈不形成簇
            2. 做法：
                1. 它由一个任意未被访问的点开始，然后探索这个点的 ε-邻域，如果 ε-邻域里有足够的点，则建立一个新的聚类，否则这个点被标签为杂音。
                2. 注意，这个杂音点之后可能被发现在其它点的 ε-邻域里，而该 ε-邻域可能有足够的点，届时这个点会被加入该聚类中。
            3. 优缺点：
                1. 优点：对噪声不敏感
                2. 缺点：聚类的结果与参数有很大关系
