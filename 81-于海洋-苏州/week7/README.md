# Week7

## SIFT

Sift（尺度不变特征变换），全称是Scale Invariant Feature Transform

1. 对视角变化、噪声等也存在一定程度的稳定性；
2. 独特性，信息量丰富，适用于在海量特征数据中进行快速，准确的匹配；
3. 多量性，即使少数几个物体也可以产生大量的Sfit特征向量；


1. 生成高斯差分金字塔（DOG金字塔），尺度空间构建
2. 空间极值点检测（关键点的初步查探）
3. 稳定关键点的精确定位
4. 稳定关键点方向信息分配
5. 关键点描述
6. 特征点匹配

## 最小二乘法

最小二乘法（Least Square Method）   
(Xi,Yi)(i...m)  | h(x) = kx + b   
残差：r = h(Xi) - Yi   
拟合程度，用通俗的话来讲，就是我们的拟合函数h(x)与待求解的函数y之间的相似性。那么 2-范数越小，自然相似性就比较高了。
r 越小 拟合程度越大

## Ransac

随机采样一致性（random sample consensus） (穷举法)

RANSAC是一种思想，一个求解已知模型的参数的框架。它不限定某一特定的问题，可以是计
算机视觉的问题，同样也可以是统计数学，甚至可以是经济学领域的模型参数估计问题。

它是一种迭代的方法，用来在一组包含离群的被观测数据中估算出数学模型的参数。 RANSAC
是一个非确定性算法，在某种意义上说，它会产生一个在一定概率下合理的结果，其允许使用
更多次的迭代来使其概率增加。

- 步骤

1. 在数据中随机选择几个点设定为内群
2. 计算适合内群的模型 e.g. y=ax+b ->y=2x+3 y=4x+5
3. 把其它刚才没选到的点带入刚才建立的模型中，计算是否为内群 e.g. hi=2xi+3->ri
4. 记下内群数量
5. 重复以上步骤
6. 比较哪次计算中内群数量最多,内群最多的那次所建的模型就是我们所要求的解

注意： 不同问题对应的数学模型不同，因此在计算模型参数时方法必定不同，RANSAC的作用在于
计算模型参数。（这导致ransac的缺点在于要求数学模型已知）

- 推理过程

1. 假设每个点是真正内群的概率为 w：w = 内群的数目/（内群数目+外群数目）
2. 通常我们不知道 w 是多少, w^n是所选择的n个点都是内群的机率, 1-w^n 是所选择的n个点至少有一个
   不是内群的机率, (1 − w^n)^k 是表示重复 k 次都没有全部的n个点都是内群的机率, 假设算法跑 k 次以后
   成功的机率是p，那么, 1 − p = (1 − w^n)^k =>  p = 1 − (1 − w^n)^k
3. 我们可以通过P反算得到抽取次数K，K=log(1-P)/log(1-w^n)。
4. 所以如果希望成功机率高：当n不变时，k越大，则p越大； 当w不变时，n越大，所需的k就越大。通常w未知，所以n 选小一点比较好。

- 优点  
  它能鲁棒的估计模型参数。例如，它能从包含大量局外点的数据集中估计出高精度的参数
- 缺点

1. 它计算参数的迭代次数没有上限；如果设置迭代次数的上限，得到的结果可能不是最优的结果，甚
   至可能得到错误的结果。
2. RANSAC只有一定的概率得到可信的模型，概率与迭代次数成正比。
3. 它要求设置跟问题相关的阀值。
4. RANSAC只能从特定的数据集中估计出一个模型，如果存在两个（或多个）模型，RANSAC不能找到
   别的模型。
5. 要求数学模型已知

## Hash

### 均值Hash

- 步骤

1. 图片缩放到 8*8
2. 灰度化
3. 求平均值
4. 比较 像素大于均值 记为1 小于均值设置为 0

### 插值Hash

- 步骤

1. 图片缩放 8*9
2. 转灰度图
3. 每行 像素值大于后一个记作1 一行9个元素
4. 生成hash

### 汉明距离
两个整数之间的汉明距离指的是这两个数字对应 *二进制位不同的位置的数目。*